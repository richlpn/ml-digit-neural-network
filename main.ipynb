{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from typing import NamedTuple, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images = npt.NDArray[np.int16]\n",
    "# Layer = NamedTuple('Layer', [\n",
    "#     ('weight', npt.NDArray[np.float32]),\n",
    "#     ('bias', npt.NDArray[np.float32]),\n",
    "#     ('activation', Callable),\n",
    "#     ('back_prop', Callable)\n",
    "# ]\n",
    "# )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN (Perceptron) implementation\n",
    "- 2 layers (with 10 neurons each)\n",
    "    - Hidden layer (Size of the amount of pixel it image has )\n",
    "    - Output layer (indicates one digit from 0 to 9)\n",
    "- 784 inputs (1 image of 28x28 pixels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    weight: npt.NDArray[np.float32]\n",
    "    bias: npt.NDArray[np.float32]\n",
    "    activation: Callable\n",
    "    derivate: Callable\n",
    "\n",
    "    def __init__(self, \n",
    "                 weight: npt.NDArray[np.float32],\n",
    "                 bias: npt.NDArray[np.float32]) -> None:\n",
    "        \n",
    "        self.weight = weight\n",
    "        self.bias = bias\n",
    "\n",
    "        self.activation = self._ReLU\n",
    "        self.derivate = self._ReLU_derive\n",
    "        \n",
    "\n",
    "    def _ReLU(self, input: np.ndarray) -> np.ndarray:\n",
    "        return np.maximum(0, input)\n",
    "    \n",
    "    def _ReLU_derive(self, z: np.ndarray):\n",
    "        return z > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "\n",
    "    _layers = list[Layer]\n",
    "    _inputs: npt.NDArray[np.float32]\n",
    "    _bias: npt.NDArray[np.float32]\n",
    "\n",
    "    def _normalize(self, arr: Images) -> npt.NDArray[np.float32]:\n",
    "        \"\"\"Normalize a array with N number \"\"\"\n",
    "        ...\n",
    "\n",
    "    def _encode_target(self, target: Images) -> npt.NDArray[np.int8]:\n",
    "        \"\"\"One hot encoding of the target predictions\"\"\"\n",
    "        enc = np.zeros((target.size, target.max() + 1)) # array of N labels\n",
    "        enc[np.arange(target.size), target] = 1 # insert 1 in the position that represents the label\n",
    "        return enc.astype(np.int8).T # As coluns\n",
    "\n",
    "\n",
    "    def __init__(self, inputs: Images, target: Images) -> None:\n",
    "\n",
    "        self._inputs = self._normalize(inputs)\n",
    "        self._targets = self._encode_target(target)\n",
    "        self._layers = []\n",
    "\n",
    "    def add_layer(self, neurons_size: int ,inputs_size: int, actvation: Callable, back: Callable):\n",
    "        weight = np.random.rand(neurons_size, inputs_size).astype('float32')\n",
    "        bias = np.random.rand(neurons_size, 1).astype('float32')\n",
    "        layer = Layer(weight, bias)\n",
    "        self._layers.append(layer)\n",
    "\n",
    "    def foward_propagation(self, layer: Layer, input: np.ndarray):\n",
    "        layer.z  = layer.weight.dot(input) + layer.bias\n",
    "        layer.a = layer.activation(z)\n",
    "        return\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aux Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(data: Images, test_size: int) -> tuple[tuple[Images, Images], tuple[Images, Images]]:\n",
    "    \"\"\"Split the data randomly into train and test data\"\"\"\n",
    "    data = data.copy()\n",
    "    rows, cols = data.shape\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    data_test = data[0: test_size].T\n",
    "    x_test = data_test[1: cols]\n",
    "    y_test = data_test[0]\n",
    "\n",
    "    data_train = data[1000: rows].T\n",
    "    x_train = data_train[1: cols]\n",
    "    y_train = data_train[0]\n",
    "\n",
    "    # Split data into labels and input data\n",
    "    return (x_train, y_train), (x_test, y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset's with the pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(pd.read_csv('./digit-recognizer/train.csv', sep=',').astype('int16'))\n",
    "test = pd.read_csv('./digit-recognizer/test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transponding dataset so each column is a example image\n",
    "\n",
    "- Also shuffling the dataset (Prevent overfitting while spliting between train and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = get_train_test_data(data, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999685329440432"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(NeuralNetwork.NEURONS_SIZE, x_train.shape[0]).max()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bbe710e9813265a6a5e2ce498926d4cd76dac7af6752690d88ab9309565465d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
